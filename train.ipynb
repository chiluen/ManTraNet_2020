{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transforms_enhance as T\n",
    "from removal import RemoveTransform\n",
    "from coco_dataset import CopyMoveDataset, SplicingDataset\n",
    "from gen_patches import DresdenDataset\n",
    "from model_ASPP import create_model, model_load_weights\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=11.56s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=12.65s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# removal dataset\n",
    "rm_train_transform = RemoveTransform('/home/jayda960825/Documents/irregular_mask/disocclusion_img_mask/')\n",
    "rm_train_dataset = DresdenDataset('/home/jayda960825/Documents/Dresden/dresden/train', 256, 256, transform=rm_train_transform)\n",
    "\n",
    "# enhancement dataset\n",
    "man_list = [T.Blur(),\n",
    "            T.MorphOps(),\n",
    "            T.Noise(),\n",
    "            T.Quantize(),\n",
    "            T.AutoContrast(),\n",
    "            T.Equilize(),\n",
    "            T.Compress()]\n",
    "en_train_transform = T.Enhance(man_list, '/home/jayda960825/Documents/irregular_mask/disocclusion_img_mask/')\n",
    "en_train_dataset = DresdenDataset('/home/jayda960825/Documents/Dresden/dresden/train', 256, 256, transform=en_train_transform)\n",
    "\n",
    "json_path = \"/home/jayda960825/coco/annotations/instances_train2017.json\"\n",
    "pic_path = \"/home/jayda960825/coco/train2017\"\n",
    "\n",
    "# copy-move dataset\n",
    "cp_train_dataset = CopyMoveDataset(json_path, pic_path, 256, 256)\n",
    "\n",
    "# splicing dataset\n",
    "sp_train_dataset = SplicingDataset(json_path, pic_path ,256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "rm_train_dataloader = DataLoader(rm_train_dataset, batch_size=2, shuffle=True)\n",
    "en_train_dataloader = DataLoader(en_train_dataset, batch_size=2, shuffle=True)\n",
    "cp_train_dataloader = DataLoader(cp_train_dataset, batch_size=2, shuffle=True)\n",
    "sp_train_dataloader = DataLoader(sp_train_dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infinite_iter(dataloader):\n",
    "    it = iter(dataloader)\n",
    "    while True:\n",
    "        try:\n",
    "            ret = next(it)\n",
    "            yield ret\n",
    "        except StopIteration:\n",
    "            it = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_train_iter = infinite_iter(rm_train_dataloader)\n",
    "en_train_iter = infinite_iter(en_train_dataloader)\n",
    "cp_train_iter = infinite_iter(cp_train_dataloader)\n",
    "sp_train_iter = infinite_iter(sp_train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from val_dataset import VAL_Dataset\n",
    "rm_val = VAL_Dataset('/home/jayda960825/Documents/Dresden/dresden/rm_val')\n",
    "\n",
    "en_val = VAL_Dataset('/home/jayda960825/Documents/Dresden/dresden/en_val')\n",
    "\n",
    "sp_val = VAL_Dataset('/home/jayda960825/Documents/Sliced_val_coco')\n",
    "\n",
    "cp_val = VAL_Dataset('/home/jayda960825/Documents/Copymove_val_coco')\n",
    "\n",
    "num_imgs = rm_val.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# img, mask = next(sp_train_iter)\n",
    "# print(img.shape, mask.shape)\n",
    "\n",
    "# plt.imshow(img[1].numpy().transpose(1, 2, 0))\n",
    "# plt.show()\n",
    "# plt.imshow(mask[1].numpy().transpose(1, 2, 0).squeeze(), cmap='gray')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def train(model, optim, num_iter, iters, criterion, epochs = 30, valid_loss_min = np.Inf):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for i in range(num_iter):\n",
    "            rm_img, rm_masking = next(iters['rm'])\n",
    "            en_img, en_masking = next(iters['en'])\n",
    "            cp_img, cp_masking = next(iters['cp'])\n",
    "            sp_img, sp_masking = next(iters['sp'])\n",
    "\n",
    "            img = torch.cat([rm_img, en_img, cp_img, sp_img], dim=0)\n",
    "            gt_masking = torch.cat([rm_masking, en_masking, cp_masking, sp_masking], dim=0)\n",
    "            img = img.cuda()\n",
    "            gt_masking = gt_masking.cuda()\n",
    "            pred_masking = model(img)\n",
    "            loss = criterion(pred_masking, gt_masking)\n",
    "\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            print(i, loss.item())\n",
    "\n",
    "        model.eval()\n",
    "        valid_loss = 0.0\n",
    "        for i in tqdm(range(num_imgs)):\n",
    "            cp_img, cp_masking = cp_val.__getitem__(i)\n",
    "            sp_img, sp_masking = sp_val.__getitem__(i)\n",
    "            rm_img, rm_masking = rm_val.__getitem__(i)\n",
    "            en_img, en_masking = en_val.__getitem__(i)\n",
    "            \n",
    "            img = torch.cat([rm_img.unsqueeze(0), en_img.unsqueeze(0), cp_img.unsqueeze(0), sp_img.unsqueeze(0)], dim=0)\n",
    "            gt_masking = torch.cat([rm_masking.unsqueeze(0), en_masking.unsqueeze(0), cp_masking.unsqueeze(0), sp_masking.unsqueeze(0)], dim=0)\n",
    "            img = img.cuda()\n",
    "            gt_masking = gt_masking.cuda()\n",
    "            with torch.no_grad():\n",
    "                pred_masking = model(img)\n",
    "            loss = criterion(pred_masking, gt_masking)\n",
    "            \n",
    "            valid_loss += loss.item()\n",
    "            \n",
    "        valid_loss = valid_loss/num_imgs\n",
    "        if valid_loss <= valid_loss_min:\n",
    "                print('validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min, valid_loss))\n",
    "                torch.save(model.state_dict(), 'mantra.pth')\n",
    "                valid_loss_min = valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: freeze feature extraction part, trainable=False\n",
      "0 0.82274329662323\n",
      "1 0.8494170904159546\n",
      "2 0.6435744166374207\n",
      "3 0.5568759441375732\n",
      "4 0.6096160411834717\n",
      "5 0.45369720458984375\n",
      "6 0.4626481533050537\n",
      "7 0.3677751123905182\n",
      "8 0.3390902876853943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1691 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0.3509153425693512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1691/1691 [07:09<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss decreased (inf --> 0.492937).  Saving model ...\n",
      "0 0.3464866578578949\n",
      "1 0.3973553776741028\n",
      "2 0.2885802388191223\n",
      "3 0.3403049111366272\n",
      "4 0.27498775720596313\n",
      "5 0.2650032341480255\n",
      "6 0.2416774481534958\n",
      "7 0.29172876477241516\n",
      "8 0.33813318610191345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1691 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0.22235846519470215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1691/1691 [07:21<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss decreased (0.492937 --> 0.334739).  Saving model ...\n",
      "0 0.26020199060440063\n",
      "1 0.2650594115257263\n",
      "2 0.28586041927337646\n",
      "3 0.37279418110847473\n",
      "4 0.4683917164802551\n",
      "5 0.2579246163368225\n",
      "6 0.25195205211639404\n",
      "7 0.2217407077550888\n",
      "8 0.24154554307460785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1691 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0.37168389558792114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 271/1691 [01:09<06:05,  3.89it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0d1638e0323d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m          \u001b[0;34m'cp'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcp_train_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m          'sp': sp_train_iter,}\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmantranet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-8ff5cdb93e21>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optim, num_iter, iters, criterion, epochs, valid_loss_min)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mpred_masking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_masking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_masking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mvalid_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2076\u001b[0m     return torch._C._nn.binary_cross_entropy(\n\u001b[0;32m-> 2077\u001b[0;31m         input, target, weight, reduction_enum)\n\u001b[0m\u001b[1;32m   2078\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2079\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "mantranet = create_model(4, True)\n",
    "mantranet = model_load_weights('/home/jayda960825/ManTraNet_2020/pretrained_weights/ManTraNet_Ptrain4.h5', mantranet)\n",
    "optim = torch.optim.Adam(mantranet.parameters(), lr = 1e-04)\n",
    "criterion = nn.BCELoss()\n",
    "iters = {'rm': rm_train_iter,\n",
    "         'en': en_train_iter,\n",
    "         'cp': cp_train_iter,\n",
    "         'sp': sp_train_iter,}\n",
    "train(mantranet, optim, 10, iters, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
